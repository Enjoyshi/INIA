{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Lab 01: Linear Regression <br> <small>RÃ©da DEHAK<br> 10 mai 2021</small> </center>\n",
    "\n",
    "The goal of this lab is :\n",
    "    - Implement a linear regression\n",
    "    - Try different version of the gradient descent algorithm\n",
    "    \n",
    "We will use a data file that contain different measurements of height (variable y) of an individual sample according to the age (variable x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fin = open('data.pkl', 'rb')\n",
    "x = pickle.load(fin)\n",
    "y = pickle.load(fin)\n",
    "fin.close()\n",
    "print(\"shape(x) : \", x.shape)\n",
    "print(\"shape(y) : \", y.shape)\n",
    "plt.plot(x, y, 'x')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Height')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "We will implement a linear regression for this problem, you know that the linear \n",
    "regression assumes that the observed variable $y$ is a linear combination of the \n",
    "vector of observation $x$\n",
    "\n",
    "$$f(x) = x^TA =\\sum_{d=1}^D a_{[d]} x_{[d]}$$\n",
    "with $x_{[D]} = 1$\n",
    "\n",
    "The linear regression consists in finding the parameters $A$ which minimizes the \n",
    "quadratic error:\n",
    "$$E(A) = \\sum_{i=1}^{N}\\left(f(x_i) - y_i\\right)^2$$\n",
    "\n",
    "we will solve this problem using two different methods:\n",
    "\n",
    "**1. Exact solution:**\n",
    "\n",
    "The vector $A$ which minimize $E(A)$ is defined as follow:\n",
    "$$A = (XX^T)^{-1}X Y$$\n",
    "\n",
    "where \n",
    "$$X=\\left[\\begin{matrix}\n",
    "x_1 & x_2 & ... & x_N\\\\\n",
    "1   &  1  & ... &  1\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "$$Y=\\left[\\begin{matrix}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    "...\\\\\n",
    "y_N\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "**a-** Compute the vector $A$ wich minimize $E(A)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "Y = ...\n",
    "A = ...\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b-** Plot in the same figure the training data and the straight \n",
    "line corresponding to the obtained $A$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(A, x):\n",
    "    ...\n",
    "\n",
    "\n",
    "plt.plot(x, y, 'x', c='blue')\n",
    "pred = predict(A, x)\n",
    "plt.plot(x, pred, c='red')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Height')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c-** Predict the height of a person of age 3.5 and that of age 7? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"height(3.5) = \", ...)\n",
    "print(\"height(7) = \", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Gradient Descent :**\n",
    "In this part, we will use the gradient descent algorithm (see convex optimization course) to find the best regression parameters. We will use the batch learning. \n",
    "\n",
    "**a-** Give the recurrence formula for $A$ of the algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ A_n = ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b-** Implement a gradient descent with a learning rate $\\eta = 0.07$ \n",
    "and starting from the origin of the space $A = 0$? Wait until the convergence of the algorithm? (print at each iteration, the number of iteration, the Error and the norm of the gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c-** Did you obtain the same result as question 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d-** To understand the gradient descent, we will display in 3D the curve of the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "error = np.zeros((100,100))\n",
    "a0 = np.linspace(-.2, .45, 100)\n",
    "a1 = np.linspace(-.1, 1, 100)\n",
    "for i in range(a0.shape[0]):\n",
    "    for j in range(a1.shape[0]):\n",
    "        A = np.array([[a0[i]],[a1[j]]])\n",
    "        error[i, j] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib import interactive\n",
    "A0, A1 = np.meshgrid(a0, a1)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(A0, A1, error.T, cmap=cm.jet, rstride=1, cstride=1)\n",
    "ax.set_xlabel('A0')\n",
    "ax.set_ylabel('A1')\n",
    "interactive(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see different views of the plot using the mouse in the interactive mode\n",
    "\n",
    "**e-** What is the link between this figure and different values of $A$ founded during the iterations of the gradient descent algorithm? Plot the path obtained using the different values of $A$ in the same figure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "A0, A1 = np.meshgrid(a0, a1)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(A0, A1, error.T , cmap=cm.jet, rstride=1, cstride=1)\n",
    "ax.plot3D(... , color ='red')\n",
    "ax.set_xlabel('A0')\n",
    "ax.set_ylabel('A1')\n",
    "interactive(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f-** Conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g-** How can we improve the speed of convergence? implement this new method and compare the result with the previous decent algorithm? Plot the path obtained using the different values of A in the same figure for the two algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "A0, A1 = np.meshgrid(a0, a1)\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(A0, A1, error.T , cmap=cm.jet, rstride=1, cstride=1)\n",
    "ax.plot3D(... , color ='red')\n",
    "ax.plot3D(... , color ='green')\n",
    "ax.set_xlabel('A0')\n",
    "ax.set_ylabel('A1')\n",
    "interactive(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h-** To run a linear Regression you can also use the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression(fit_intercept = False).fit(X.T, Y)\n",
    "print(\"A = \", reg.coef_)\n",
    "print(\"height(3.5) = \", reg.predict(np.array([[3.5, 1]])))\n",
    "print(\"height(7) = \", reg.predict(np.array([[7, 1]])))\n",
    "print(\"Score = \", reg.score(X.T, y.reshape((50,1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39tf2",
   "language": "python",
   "name": "py39tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
